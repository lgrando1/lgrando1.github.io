<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IA | Leonardo Grando</title>
    <link>https://lgrando1.github.io/tag/ia/</link>
      <atom:link href="https://lgrando1.github.io/tag/ia/index.xml" rel="self" type="application/rss+xml" />
    <description>IA</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 30 Sep 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://lgrando1.github.io/media/icon_hu833f70911ce8d7c0b3dbb80c9eadb7d3_197124_512x512_fill_lanczos_center_3.png</url>
      <title>IA</title>
      <link>https://lgrando1.github.io/tag/ia/</link>
    </image>
    
    <item>
      <title>Como Instalar e Usar um modelo LLMs Offline no Android</title>
      <link>https://lgrando1.github.io/post/llmandroid/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/llmandroid/</guid>
      <description>&lt;p&gt;Outros posts sobre o tema em:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/hface/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Como Criar um Pipeline em Python para Testar Modelos no Hugging Face&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/prompt1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dicas de Engenharia de Prompt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollama/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 1 - Instalando o Ollama no Linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollamawin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 2 - Instalando o Ollama no Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Importante: Nunca utilizar LLMs como oráculos ou como fonte de informações, já encontrei vários erros tanto em modelos online ou offline. Usar apenas como suporte para suas atividades.&lt;/p&gt;
&lt;p&gt;Depois de testar LLMs offlines no computador, resolvi procurar uma solução para meu celular. O dispositivo em questão é um celular Android da Marca Samsung &lt;a href=&#34;https://www.samsung.com/br/smartphones/galaxy-a/galaxy-a15-blue-black-256gb-sm-a155mzkizto/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelo A15 (SM-A155M/DSN)&lt;/a&gt;. O mesmo é um dispositivo que me custou um pouco menos de 1000 reais e o possui 8 gigas de RAM, em meus testes a quantidade de RAM influenciou no desempenho, com 8 GB tive sucesso em modelos de no máximo 4B de paramêtros, testei um de 7B e ele ficou muito lerdo para gerar a inferência. Sobre dispositivos com 4 gigas de RAM fiz um teste e descrevo no item 15.&lt;/p&gt;
&lt;p&gt;Existem &lt;a href=&#34;https://www.reddit.com/r/LocalLLaMA/search/?q=smartphone&amp;amp;type=link&amp;amp;cId=cf9557fb-9775-4a60-8095-c8c0c62a65fa&amp;amp;iId=cc07fcca-916b-44b7-9e36-ddad34b28746&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bastante discussões sobre este tema, como por exemplo em&lt;/a&gt; onde conheci este aplicativo, o &lt;a href=&#34;https://play.google.com/store/apps/details?id=com.druk.lmplayground&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LM Playground&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Lembrando que é uma solução experimental e encontrei vários problemas como demora de respostas e muitas vezes ele alucinava ou não finalizava a inferência. Dependendo o poder computacional do dispositivo onde está sendo realizado o teste, ele pode não conseguir inferir dependendo o modelo LLM. Testei um Modelo de 7B no meu celular e ele ficou muito lento.&lt;/p&gt;
&lt;p&gt;Caso queira ver o aplicativo em ação, segue um &lt;a href=&#34;https://youtu.be/ibQVCXG6Ixk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vídeo que gravei testando o aplicativo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Para instalar:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entrar na PlayStore:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Playstore&#34; srcset=&#34;
               /post/llmandroid/01_hub527ee1d1d6e54a235fa7f35611ff2f2_376361_7ab24a318c01590d3f9027b32243a7d6.webp 400w,
               /post/llmandroid/01_hub527ee1d1d6e54a235fa7f35611ff2f2_376361_cc0737c7cde99e51f2c18390e6a3bdab.webp 760w,
               /post/llmandroid/01_hub527ee1d1d6e54a235fa7f35611ff2f2_376361_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/01_hub527ee1d1d6e54a235fa7f35611ff2f2_376361_7ab24a318c01590d3f9027b32243a7d6.webp&#34;
               width=&#34;347&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Procurar o Aplicativo &amp;ldquo;LM Playgroung&amp;rdquo;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;busca&#34; srcset=&#34;
               /post/llmandroid/02_huaeb09686932f799d57f1144d67af95cd_78512_470f70c604f5da566b6a59da09f05d28.webp 400w,
               /post/llmandroid/02_huaeb09686932f799d57f1144d67af95cd_78512_04f69119b56277c447ae3c38b3fa01dd.webp 760w,
               /post/llmandroid/02_huaeb09686932f799d57f1144d67af95cd_78512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/02_huaeb09686932f799d57f1144d67af95cd_78512_470f70c604f5da566b6a59da09f05d28.webp&#34;
               width=&#34;344&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Instalar o App:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;instalar&#34; srcset=&#34;
               /post/llmandroid/03_hu28007a23171c8859327775c15de95929_186321_b73036923e961e151eb5c8d8206f9d70.webp 400w,
               /post/llmandroid/03_hu28007a23171c8859327775c15de95929_186321_4695137c65c6d60f9e37430969f303b3.webp 760w,
               /post/llmandroid/03_hu28007a23171c8859327775c15de95929_186321_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/03_hu28007a23171c8859327775c15de95929_186321_b73036923e961e151eb5c8d8206f9d70.webp&#34;
               width=&#34;345&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Abrir o App e clicar em &amp;ldquo;Select Model&amp;rdquo;:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;selecionar&#34; srcset=&#34;
               /post/llmandroid/04_hue58ef2008f65ad1adc7d7db7adf6b956_30621_0811220416f0a2d44ec20ebe04b60ff6.webp 400w,
               /post/llmandroid/04_hue58ef2008f65ad1adc7d7db7adf6b956_30621_36acd4b481bd51027bea3d10d692d0c0.webp 760w,
               /post/llmandroid/04_hue58ef2008f65ad1adc7d7db7adf6b956_30621_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/04_hue58ef2008f65ad1adc7d7db7adf6b956_30621_0811220416f0a2d44ec20ebe04b60ff6.webp&#34;
               width=&#34;349&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Abrira os modelos disponíveis no APP (OBS: a versão Beta do aplicativo possui mais modelos disponiveis, ver item 13):&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/05_hu2050179f93f3abe8cf29dd84a87370e8_96705_1f4f3811ff57af0853e1ee1d5da82ae6.webp 400w,
               /post/llmandroid/05_hu2050179f93f3abe8cf29dd84a87370e8_96705_e5cad5455761db352d57379ad2425a6e.webp 760w,
               /post/llmandroid/05_hu2050179f93f3abe8cf29dd84a87370e8_96705_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/05_hu2050179f93f3abe8cf29dd84a87370e8_96705_1f4f3811ff57af0853e1ee1d5da82ae6.webp&#34;
               width=&#34;339&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;Clicar em baixar um modelo e esperar baixar:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/06_hu54ef596dcf83e5a8ac55ad590e802d42_27492_a4c178947b9bf98b0ff70aafe95d8cdf.webp 400w,
               /post/llmandroid/06_hu54ef596dcf83e5a8ac55ad590e802d42_27492_22bf8bc1bc1200f878cd1107218e36a1.webp 760w,
               /post/llmandroid/06_hu54ef596dcf83e5a8ac55ad590e802d42_27492_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/06_hu54ef596dcf83e5a8ac55ad590e802d42_27492_a4c178947b9bf98b0ff70aafe95d8cdf.webp&#34;
               width=&#34;342&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Aparecerá que o modelo foi baixado:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/07_hu8e1c6eaafe3ec871a622bf630cff0ca3_91285_265654a13b54783461e043f55e4a3a20.webp 400w,
               /post/llmandroid/07_hu8e1c6eaafe3ec871a622bf630cff0ca3_91285_83ed6c86942a4ab18875d42f9f536112.webp 760w,
               /post/llmandroid/07_hu8e1c6eaafe3ec871a622bf630cff0ca3_91285_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/07_hu8e1c6eaafe3ec871a622bf630cff0ca3_91285_265654a13b54783461e043f55e4a3a20.webp&#34;
               width=&#34;335&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;O Aplicativo baixa o modelo na sua pasta de Download, se você quiser apagar um modelo baixado, precisa deletar no seu gerenciador de dispositivos:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/08_hu1fccb15cac86a6568ae60e668702655f_46528_2ac8cb5347c2e2765bb59a72b7c69898.webp 400w,
               /post/llmandroid/08_hu1fccb15cac86a6568ae60e668702655f_46528_a656fe4cf25edb4b6a7f645d32e9dbc6.webp 760w,
               /post/llmandroid/08_hu1fccb15cac86a6568ae60e668702655f_46528_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/08_hu1fccb15cac86a6568ae60e668702655f_46528_2ac8cb5347c2e2765bb59a72b7c69898.webp&#34;
               width=&#34;343&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;Para garantir que não ocorra conexão, para fins de teste:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/09_huaef1c77c92899c40f01235798a74b320_59255_f0fd2f492012baedbd5f235692dd4844.webp 400w,
               /post/llmandroid/09_huaef1c77c92899c40f01235798a74b320_59255_dfd5e6a0a4a3f69e1d8cc76599c15605.webp 760w,
               /post/llmandroid/09_huaef1c77c92899c40f01235798a74b320_59255_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/09_huaef1c77c92899c40f01235798a74b320_59255_f0fd2f492012baedbd5f235692dd4844.webp&#34;
               width=&#34;339&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;Abrir novamente o aplicativo e escolher o modelo:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/10_hu26c0839d237045b963d276023d088c3c_80454_0a6ca357c432bc46d32fea8b3950eea5.webp 400w,
               /post/llmandroid/10_hu26c0839d237045b963d276023d088c3c_80454_9c2767ce7e8fee63d6f7965cc8d17388.webp 760w,
               /post/llmandroid/10_hu26c0839d237045b963d276023d088c3c_80454_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/10_hu26c0839d237045b963d276023d088c3c_80454_0a6ca357c432bc46d32fea8b3950eea5.webp&#34;
               width=&#34;344&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;Agora você pode começar a utilizar o modelo como se fosse um chat.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/11_hufc6a095ce55180404d2c491b3825924d_109988_047f9960c313a6543d1dee6ff53b684d.webp 400w,
               /post/llmandroid/11_hufc6a095ce55180404d2c491b3825924d_109988_b6f5bf1918ec671d3b50bbdcf9b014f3.webp 760w,
               /post/llmandroid/11_hufc6a095ce55180404d2c491b3825924d_109988_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/11_hufc6a095ce55180404d2c491b3825924d_109988_047f9960c313a6543d1dee6ff53b684d.webp&#34;
               width=&#34;340&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;12&#34;&gt;
&lt;li&gt;Ao clicar no simbolo do aplicativo ou no sinal de exclamação, você pode avaliar a métrica de performance do modelo:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/13_hu23caca9b2fdbd13e61baf3f902f05eff_132700_01d006ce93667d5b20667a6f71017cbb.webp 400w,
               /post/llmandroid/13_hu23caca9b2fdbd13e61baf3f902f05eff_132700_d70acc339adb666dafc3a9fdc0420c99.webp 760w,
               /post/llmandroid/13_hu23caca9b2fdbd13e61baf3f902f05eff_132700_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/13_hu23caca9b2fdbd13e61baf3f902f05eff_132700_01d006ce93667d5b20667a6f71017cbb.webp&#34;
               width=&#34;339&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/14_hue3140880317ad18eac1379d4af16d94b_121874_d93d2340e3104cbb2f491aa53c274e0f.webp 400w,
               /post/llmandroid/14_hue3140880317ad18eac1379d4af16d94b_121874_fc3281f9ed673e503aeedf72af5e5998.webp 760w,
               /post/llmandroid/14_hue3140880317ad18eac1379d4af16d94b_121874_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/14_hue3140880317ad18eac1379d4af16d94b_121874_d93d2340e3104cbb2f491aa53c274e0f.webp&#34;
               width=&#34;346&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;13&#34;&gt;
&lt;li&gt;Entrei como testador beta do LM Playground e após a atualização do aplicativo apareceu novos modelos LLMs para testar:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/16_huf73849f28aa801e7cd7fe580f12c24b6_147867_4530ee6cbf090a8bdd78b61989d6bcd2.webp 400w,
               /post/llmandroid/16_huf73849f28aa801e7cd7fe580f12c24b6_147867_993f4ac209920cab35d8222647bcb3ec.webp 760w,
               /post/llmandroid/16_huf73849f28aa801e7cd7fe580f12c24b6_147867_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/16_huf73849f28aa801e7cd7fe580f12c24b6_147867_4530ee6cbf090a8bdd78b61989d6bcd2.webp&#34;
               width=&#34;341&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/17_hu5c6b2fc8526325b06204ca39671be2f6_115804_665480f98e89c28b8c36336718e78a66.webp 400w,
               /post/llmandroid/17_hu5c6b2fc8526325b06204ca39671be2f6_115804_4a69736d68886bdea7c95fa4c2d9b611.webp 760w,
               /post/llmandroid/17_hu5c6b2fc8526325b06204ca39671be2f6_115804_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/17_hu5c6b2fc8526325b06204ca39671be2f6_115804_665480f98e89c28b8c36336718e78a66.webp&#34;
               width=&#34;334&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;Testei a &lt;a href=&#34;https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Llama3.2 3B&lt;/a&gt; e gostei do desempenho em meu celular:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/18_hu8361c130e74de38ce150e8063f2dde55_126250_8f37edde62259e342f24abb6229cdef3.webp 400w,
               /post/llmandroid/18_hu8361c130e74de38ce150e8063f2dde55_126250_455dfb31e96ed32ae2ffc2847004fc15.webp 760w,
               /post/llmandroid/18_hu8361c130e74de38ce150e8063f2dde55_126250_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/18_hu8361c130e74de38ce150e8063f2dde55_126250_8f37edde62259e342f24abb6229cdef3.webp&#34;
               width=&#34;339&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/19_huf50abbce892824360682e9b752b8e359_157538_dac40b7fb360f8f95ea859aa4c2d83ba.webp 400w,
               /post/llmandroid/19_huf50abbce892824360682e9b752b8e359_157538_54136c5ce3bab4b7526c98fba14f96f6.webp 760w,
               /post/llmandroid/19_huf50abbce892824360682e9b752b8e359_157538_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/19_huf50abbce892824360682e9b752b8e359_157538_dac40b7fb360f8f95ea859aa4c2d83ba.webp&#34;
               width=&#34;343&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/20_hu5af747e17d07409d7d42c9bd52c56dd1_98919_4f9c0f9c135caf756d21fd89f3c9f09c.webp 400w,
               /post/llmandroid/20_hu5af747e17d07409d7d42c9bd52c56dd1_98919_dc7b47e99d86cf1053c95932f030bd87.webp 760w,
               /post/llmandroid/20_hu5af747e17d07409d7d42c9bd52c56dd1_98919_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/20_hu5af747e17d07409d7d42c9bd52c56dd1_98919_4f9c0f9c135caf756d21fd89f3c9f09c.webp&#34;
               width=&#34;339&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;testei em um tablet da Samsung (Modelo X200 com 4 GB de RAM) e não tive sucesso com este modelo de Llama3.2 3B, mas aparentemente o Llama3.2 1B funcionou bem, o que reforça a questão empírica destes testes:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;modelos&#34; srcset=&#34;
               /post/llmandroid/30_hu28a7d012a8b0b20ef1b34a03314ddd2d_245850_d3bdf0e8d85ec21083c01c9dcdb2e3b1.webp 400w,
               /post/llmandroid/30_hu28a7d012a8b0b20ef1b34a03314ddd2d_245850_c61151b858cee99fcf7c4d5f2ac14120.webp 760w,
               /post/llmandroid/30_hu28a7d012a8b0b20ef1b34a03314ddd2d_245850_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/llmandroid/30_hu28a7d012a8b0b20ef1b34a03314ddd2d_245850_d3bdf0e8d85ec21083c01c9dcdb2e3b1.webp&#34;
               width=&#34;760&#34;
               height=&#34;475&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Sucesso a todos!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Como Instalar e Usar um modelo LLMs Offline no Windows</title>
      <link>https://lgrando1.github.io/post/ollamawin/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/ollamawin/</guid>
      <description>&lt;p&gt;Outros posts sobre o tema em:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/hface/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Como Criar um Pipeline em Python para Testar Modelos no Hugging Face&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/prompt1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dicas de Engenharia de Prompt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollama/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 1 - Instalando o Ollama no Linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/llmandroid/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 3 - Instalando LLMs Off-line no Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Após o &lt;a href=&#34;https://lgrando1.github.io/post/ollama/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;último post&lt;/a&gt; onde relatei a experiencia de usar o Ollama em num computador com Linux, resolvi extender o teste em uma máquina com Windows 10.
Fiquei interessado em saber como o Ollama iria se comportar em um computador de 2013, um Samsung NP500P4C-AD2BR, provido de um processador Core i7 de terceira geração e sem uma GPU discreta.
As únicas modificações que realizei neste computador foi a inclusão de mais 2 GB de RAM (agora com 6 gigas) e a instalação de um SSD no lugar do HD original.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;infohw&#34; srcset=&#34;
               /post/ollamawin/windownsammy_hubab50e7867f3387d1603636a64fbb609_9611_750d7388bb3053bb6d389cbb94ce95b3.webp 400w,
               /post/ollamawin/windownsammy_hubab50e7867f3387d1603636a64fbb609_9611_f7093f5662e642a4720a78f039210a7e.webp 760w,
               /post/ollamawin/windownsammy_hubab50e7867f3387d1603636a64fbb609_9611_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windownsammy_hubab50e7867f3387d1603636a64fbb609_9611_750d7388bb3053bb6d389cbb94ce95b3.webp&#34;
               width=&#34;403&#34;
               height=&#34;149&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Lembrando que o &lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ollama&lt;/a&gt; é uma ferramenta que facilita o processo de baixar e rodar os modelos LLMs de código aberto. Ele pode ser instalado no Windows, MacOS e o Linux.&lt;/p&gt;
&lt;p&gt;O processo de instalação foi bem tranquilo, baixei o instalador (são quase 700 megas) e segui o processo de instalação padrão do Windows.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;paginaollama&#34; srcset=&#34;
               /post/ollamawin/windonw_hudf41d5a215322309e276d45b7edc5ac3_48414_206cd234781c85d3080e9573a11daa2c.webp 400w,
               /post/ollamawin/windonw_hudf41d5a215322309e276d45b7edc5ac3_48414_e965494d8c6400752c36c582f5dede80.webp 760w,
               /post/ollamawin/windonw_hudf41d5a215322309e276d45b7edc5ac3_48414_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windonw_hudf41d5a215322309e276d45b7edc5ac3_48414_206cd234781c85d3080e9573a11daa2c.webp&#34;
               width=&#34;760&#34;
               height=&#34;448&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;download&#34; srcset=&#34;
               /post/ollamawin/windown2_hu6dd2f5dc0f8f2994d004fe0c403ba0f4_60647_0c6ed8d8e881e93e5ff66d3723ac0e50.webp 400w,
               /post/ollamawin/windown2_hu6dd2f5dc0f8f2994d004fe0c403ba0f4_60647_cbe5b7794cae7c3f46cf5bd44847af12.webp 760w,
               /post/ollamawin/windown2_hu6dd2f5dc0f8f2994d004fe0c403ba0f4_60647_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windown2_hu6dd2f5dc0f8f2994d004fe0c403ba0f4_60647_0c6ed8d8e881e93e5ff66d3723ac0e50.webp&#34;
               width=&#34;760&#34;
               height=&#34;448&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;paginaollama&#34; srcset=&#34;
               /post/ollamawin/windowsinstaler_hudd20e2c191b20dc6ad9bdb2ec974c889_24609_041dc2428515075ae60c0d0df5766fe8.webp 400w,
               /post/ollamawin/windowsinstaler_hudd20e2c191b20dc6ad9bdb2ec974c889_24609_d1908c4a007e758e81cbbcbdfabfb5e9.webp 760w,
               /post/ollamawin/windowsinstaler_hudd20e2c191b20dc6ad9bdb2ec974c889_24609_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windowsinstaler_hudd20e2c191b20dc6ad9bdb2ec974c889_24609_041dc2428515075ae60c0d0df5766fe8.webp&#34;
               width=&#34;760&#34;
               height=&#34;562&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Após o processo de instalação terminar, vai aparecer o icone do Ollama na sua barra de notificação. Então é só abrir o PowerShell e repetir os mesmos comandos do Linux.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;download&#34; srcset=&#34;
               /post/ollamawin/windowsserver_hu85511738daec8878c3a5e9bf464feb0b_710294_ed632c1a480e14662dcfddf21ada31ef.webp 400w,
               /post/ollamawin/windowsserver_hu85511738daec8878c3a5e9bf464feb0b_710294_631c7f64115207de0a720926c613d707.webp 760w,
               /post/ollamawin/windowsserver_hu85511738daec8878c3a5e9bf464feb0b_710294_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windowsserver_hu85511738daec8878c3a5e9bf464feb0b_710294_ed632c1a480e14662dcfddf21ada31ef.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Então solicitei para baixar e instalar o modelo &lt;a href=&#34;https://ollama.com/library/phi3.5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;phi3.5 da Microsoft&lt;/a&gt; utilizando o comando&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run &amp;lt;Nome_da_LLM&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;No caso da Phi3&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run phi3.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;O processo de instalação da LLM foi mais demorado devido a limitação da placa wifi deste computador, e aqui ele rodando, onde realizei a minha pergunta clássica para verificar os modelos LLMs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Quantos premios Nobéis o Brasil já ganhou?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;nobel&#34; srcset=&#34;
               /post/ollamawin/windowsnobel_hu2517b82405507f4283767acef5ab506f_42455_f32a3625dd7ec7812d65afda87abe535.webp 400w,
               /post/ollamawin/windowsnobel_hu2517b82405507f4283767acef5ab506f_42455_644445c5d8c6091cce26bda5a34344ed.webp 760w,
               /post/ollamawin/windowsnobel_hu2517b82405507f4283767acef5ab506f_42455_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windowsnobel_hu2517b82405507f4283767acef5ab506f_42455_f32a3625dd7ec7812d65afda87abe535.webp&#34;
               width=&#34;628&#34;
               height=&#34;440&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para testar a diferença de desempenho, solicitei a ele:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Você poderia gerar um código python para ler um arquivo excel em um dataframe pandas?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ps: Lembrando que estes modelos possuem uma grande aleatoriedade nas respostas, como poderemos ver abaixo:&lt;/p&gt;
&lt;p&gt;No Notebook com Windows, sem GPU demorou: 284 segundos e na máquina com Linux e GPU demorou 138 segundos. É vísivel a diferença na formação das frases, mas é importante observar que o mesmo modelo respondeu de forma diferente em ambas as máquinas:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Exemplo da resposta do prompt no Windows&#34; srcset=&#34;
               /post/ollamawin/windprompt_huc6ab9f2eb5c69a8238a6f22c9e88e901_59584_46f72eaeb992f5681aabda5ec9c3af71.webp 400w,
               /post/ollamawin/windprompt_huc6ab9f2eb5c69a8238a6f22c9e88e901_59584_e9451f2fe1f82a32d3238607f5ac5390.webp 760w,
               /post/ollamawin/windprompt_huc6ab9f2eb5c69a8238a6f22c9e88e901_59584_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/windprompt_huc6ab9f2eb5c69a8238a6f22c9e88e901_59584_46f72eaeb992f5681aabda5ec9c3af71.webp&#34;
               width=&#34;645&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt;&amp;gt;&amp;gt; Você poderia gerar um código python para ler um arquivo excel em um dataframe pandas?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Certamente! Abaixo está uma pequena função Python que usa &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;pandas&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; e &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;openpyxl&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;, ou
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;seja, a biblioteca de manipulação &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; Excel padrão no Python. Certifique-se primeiro
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;de ter essas bibliotecas instaladas:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;bash
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install pandas openpyxl
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Aqui está um código que lê um arquivo Excel em um DataFrame Pandas:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;A resposta completa dele:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;import pandas as pd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;def read_excel_to_dataframe&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;file_path&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Lendo o arquivo excel usando a função read_excel de pandas com engine&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;openpyxl&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; pddict.read_excel&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;file_path, &lt;span class=&#34;nv&#34;&gt;engine&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;openpyxl&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; df
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Exemplo de uso:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;arquivo_do_campo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;caminho/para/seu/arq_de_celulares.xlsx&amp;#39;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Substitua pela sua&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;localização &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; arquivo real
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;dataframe_pandas&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; readdon_excel_to_datafrane&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;fileiio_dave&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;print&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;dataframe_pandas&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Certifique-se de substituir &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;caminho/para/seu/arq_de_celulares.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; pela
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;localização real &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; seu arquivo Excel, ou seja, caminho e nome completo para o seu
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;arquivo no disco rígido.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Essa função lê diretamente um arquivo de planilha compartilhada &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;com extensão
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;.xlsx&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; usando a engine &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;openpyxl&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;, que é necessária para leituras em Python &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Excel moderno &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;.xlsx&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;. O DataFrame resultante pode então ser manipulado ou analisado
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conforme desejado.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Se você tiver apenas arquivos simples com planilhas &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;com extensão &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;.xls&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; e precisar
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;de uma versão mais antiga, poderá usar a engine &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;xlrd&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; em vez disso:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;import pandas as pd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;def read_excel_to_dataframe&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;file_path&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Lendo o arquivo excel usando a função read_excel sem especificar um engine (o&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;pandas&amp;#39;&lt;/span&gt; padrão lê com xlrd por padrão para &lt;span class=&#34;s1&#34;&gt;&amp;#39;.xls&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nv&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; pd.read_excel&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;file_path&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; df
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Exemplo de uso:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;arquivo_do_campo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;caminho/para/seu/arq_de_celulares.xls&amp;#39;&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Apenas caminho se for&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;um arquivo .xls simples
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;dataframe_pandas&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; readdon_excel_to_datafrane&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;fileiio_dave&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;print&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;dataframe_pandas&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Lembre-se de que, para ficheiros &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;.xlsx&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;, &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;openpyxl&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; é necessário e tanto o pandas
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;quanto openpyxl devem estar instalados em seu ambiente Python.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Resposta do Prompt no computador com Linux&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Exemplo de Prompt Linux&#34; srcset=&#34;
               /post/ollamawin/linprompt_hua1dba9888fe69aa87182346e3e718f0f_92928_f4fa6e246ed9c99a704cfa45bfa6f84f.webp 400w,
               /post/ollamawin/linprompt_hua1dba9888fe69aa87182346e3e718f0f_92928_d9b2de36c2be8018757ba04788d0681c.webp 760w,
               /post/ollamawin/linprompt_hua1dba9888fe69aa87182346e3e718f0f_92928_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollamawin/linprompt_hua1dba9888fe69aa87182346e3e718f0f_92928_f4fa6e246ed9c99a704cfa45bfa6f84f.webp&#34;
               width=&#34;760&#34;
               height=&#34;632&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt;&amp;gt;&amp;gt; Você poderia gerar um código python para ler um arquivo excel em um dataframe pandas?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Certamente! Abaixo está um exemplo de como você pode usar &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;pandas&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; juntamente com &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;openpyxl&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;, que é uma biblioteca Python para leitura e escrita &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Excel, especialmente adequada para arquivos &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;.xlsx&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;. Certifique-se primeiro de ter essas bibliotecas instaladas&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; se não estiverem instaladas, você 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pode adicioná-las usando &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;pip&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;bash
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install pandas openpyxl
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Aqui está um script Python simples para ler um arquivo Excel e convertê-lo em um DataFrame Pandas:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;import pandas as pd
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Substitua &amp;#39;seu_arquivo.xlsx&amp;#39; pelo nome do seu arquivo de excel reais ou o caminho até ele se estiver no disco rígido.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;nome_do_arq&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;seu_arquivo.xlsx&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Lendo um arquivo Excel usando pandas, que reconhece automaticamente a engine como openpyxl para formato .xlsx&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;df&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; pd.read extrado de excel&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;nome_do_arq&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;print&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;df.head&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Imprime as primeiras linhas do DataFrame no console; use df fora-de-caso também&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Substitua &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;seu_arquivo.xlsx&amp;#39;&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; pelo caminho absoluto ou nome relativo para seu arquivo Excel, e a variável &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;df&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; contém o conteúdo 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;de sua tabela em um objeto DataFrame Pandas com qualquer forma que você precisar realizar cálculos adicionais ou manipulações.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Se estiver lidando com muitas linhas/colunas grandes, considere usar &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;chunksize&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; para ler o arquivo por partes:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;python
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;chunk_size&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; chunk_df in pd.read_excel&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;nome_do_arq, &lt;span class=&#34;nv&#34;&gt;chunksize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;chunk_size&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Realiza alguma operação com cada parte do dataframe &amp;#39;chunk&amp;#39; aqui...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    print&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;chunk_df.head&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Se precisar verificá-lo dentro de seu loop&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sb&#34;&gt;```&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Lembre-se que esta abordagem requer um arquivo Excel sem cabeçalho dinâmico, pois por padrão &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;pd.read_excel&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; usará a primeira 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;linha como nomes das colunas&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; se sua tabela &lt;span class=&#34;k&#34;&gt;do&lt;/span&gt; excel &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; estruturada de outra forma &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;por exemplo, cada uma dessas primeiras nove 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;células é um cabeçalho&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;, você precisará lidar com isso manualmente ou especificando explicitamente os rótulos nas linhas.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Preciso validar/verificar ambos os códigos gerados, atualizarei o post com a verificação dos códigos, mas não deixa de ser interessante que é possivel rodar um LLM em uma computador com 11 anos.&lt;/p&gt;
&lt;p&gt;Sucesso a todos!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Como Instalar e Usar um modelo LLMs Offline no Linux</title>
      <link>https://lgrando1.github.io/post/ollama/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/ollama/</guid>
      <description>&lt;p&gt;Outros posts sobre o tema em:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/hface/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Como Criar um Pipeline em Python para Testar Modelos no Hugging Face&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/prompt1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dicas de Engenharia de Prompt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollamawin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 2 - Instalando o Ollama no Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/llmandroid/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 3 - Instalando LLMs Off-line no Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;O recém &lt;a href=&#34;https://www.nature.com/articles/d41586-024-02998-y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;artigo da Nature&lt;/strong&gt;&lt;/a&gt; trouxe uma discussão sobre o uso de LLMs locais em vez daquelas que utilizamos de forma online como por exemplo o Chat-GPT, Gemini e o CoPilot. A preocupação com aspectos como privacidade e o uso de nossos dados quando utilizandos os LLMs de terceitos, sem contar que estas ferramentas nescessitam de acesso a internet.
Sites como o &lt;a href=&#34;https://huggingface.co/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugging Face&lt;/a&gt; permitem testar alguns usos destas ferramentas utilizando uma biblioteca com a linguagem Python, como eu já descrevi em &lt;a href=&#34;https://lgrando1.github.io/post/hface/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;uma postagem anterior.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eu queria algo mais completo como um assistente virtual local e como sou usuário Linux (uso o Pop!_OS 20.04), encontrei este &lt;a href=&#34;https://itsfoss.com/ollama-setup-linux/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post muito bem explicado&lt;/a&gt; de como rodar uma LLM de maneira off-line no Linux e então resolvi replicar, e conto esta experiência abaixo.&lt;/p&gt;
&lt;p&gt;O &lt;a href=&#34;https://ollama.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ollama&lt;/a&gt; é uma ferramenta que facilita o processo de baixar e rodar os modelos LLMs de código aberto. Ele pode ser instalado no Windows, MacOS e o Linux. Apenas seguir o &lt;a href=&#34;https://ollama.com/download&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;procedimento de instalação presente no site deles&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;No meu caso utilizei o comando abaixo, mas recomendo que você siga o procedimento descrito pelo site pois o mesmo pode alterar conforme novas atualizações.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Repetindo: siga o procedimento de instalação conforme descrito no site deles, não este daqui&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -fsSL https://ollama.com/install.sh &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; sh 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;O código acima irá baixar o Ollama em sua máquina e rodar o script de instalação. Você pode auditar o script de &lt;a href=&#34;https://github.com/ollama/ollama/blob/main/scripts/install.sh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;instalação aqui&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A minha máquina é um notebook Acer Nitro que adquiri no final de 2020. Ele possui um Core i5 9300H, 16 GB de RAM e uma GPU Nvidia Geforce GTX 1650. O que fica interessante, pois o Ollama reconheceu a GPU.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;infohw&#34; srcset=&#34;
               /post/ollama/neofetch_huc57dbd0c962ac1aad17efa80b580855c_61989_daf0f69daa090140162d0bb870490db6.webp 400w,
               /post/ollama/neofetch_huc57dbd0c962ac1aad17efa80b580855c_61989_e0e7a9606a7a95aaa22244ecc7136c1b.webp 760w,
               /post/ollama/neofetch_huc57dbd0c962ac1aad17efa80b580855c_61989_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/neofetch_huc57dbd0c962ac1aad17efa80b580855c_61989_daf0f69daa090140162d0bb870490db6.webp&#34;
               width=&#34;626&#34;
               height=&#34;532&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Na &lt;a href=&#34;https://itsfoss.com/ollama-setup-linux/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;postagem que usei como referência&lt;/a&gt; para instalar, o autor descreve que o Notebook dele não possui uma GPU discreta, o que influenciou no desempenho. E o modelo escolhido vai também influenciar.&lt;/p&gt;
&lt;p&gt;Hora de testar se o Ollama está rodando, num browser digite:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Testando o Ollama no Browser&#34; srcset=&#34;
               /post/ollama/ollamabrowser_hu80b020927a40b57eb1a0e755609e6b5c_5448_ac09abb31baa59c3a17be38cea8a599d.webp 400w,
               /post/ollama/ollamabrowser_hu80b020927a40b57eb1a0e755609e6b5c_5448_717c5e0842dace38e55630e53f2bd880.webp 760w,
               /post/ollama/ollamabrowser_hu80b020927a40b57eb1a0e755609e6b5c_5448_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/ollamabrowser_hu80b020927a40b57eb1a0e755609e6b5c_5448_ac09abb31baa59c3a17be38cea8a599d.webp&#34;
               width=&#34;306&#34;
               height=&#34;111&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Aqui mostrou que está funcionando.&lt;/p&gt;
&lt;p&gt;Agora é hora de baixar o modelo LLM. No &lt;a href=&#34;https://ollama.com/library&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;site&lt;/a&gt; existe vários modelos. Já testei o llama3.1. Este &lt;a href=&#34;https://ollama.com/library/llama3.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;modelo desenvolvido pela Meta&lt;/a&gt; e que possui três níveis de parâmetros 8, 70 e 405 bilhões de parâmetros. Acabei escolhendo o modelo de 8B. São aproximadamente 4.7 GB utilizado de armazenamento. Mas ai fica o critério de cada um. Para este post vou apresentar o processo de instalação do modelo &lt;a href=&#34;https://ollama.com/library/phi3.5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;phi3.5 da Microsoft&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Para dar um &amp;ldquo;pull&amp;rdquo; em um modelo LLM desejado, utiliza-se o comando:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama pull &amp;lt;Nome_da_LLM&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Então para baixar e instalar o modelo &lt;a href=&#34;https://ollama.com/library/phi3.5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;phi3.5 da Microsoft&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama pull phi3.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;phi instalado&#34; srcset=&#34;
               /post/ollama/phi3_hu4521b4dd586ea2a9b9782a51cff3b5b0_38614_52705a8b42c9db27ffb2388f5986e5ae.webp 400w,
               /post/ollama/phi3_hu4521b4dd586ea2a9b9782a51cff3b5b0_38614_d91c693f3425617963bb94a2ecab009c.webp 760w,
               /post/ollama/phi3_hu4521b4dd586ea2a9b9782a51cff3b5b0_38614_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/phi3_hu4521b4dd586ea2a9b9782a51cff3b5b0_38614_52705a8b42c9db27ffb2388f5986e5ae.webp&#34;
               width=&#34;760&#34;
               height=&#34;213&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Agora vamos &lt;strong&gt;listar&lt;/strong&gt; as imagens que estão presentes no seu computador.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama list
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;LLM instaladas&#34; srcset=&#34;
               /post/ollama/ollamalist_hu49f033c139ceae7bbbe46f6319b2a075_18154_2a1604f69fde0f35f72685ae79b87aaa.webp 400w,
               /post/ollama/ollamalist_hu49f033c139ceae7bbbe46f6319b2a075_18154_d6645b5a7868aa6685f360d87c1bfc76.webp 760w,
               /post/ollama/ollamalist_hu49f033c139ceae7bbbe46f6319b2a075_18154_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/ollamalist_hu49f033c139ceae7bbbe46f6319b2a075_18154_2a1604f69fde0f35f72685ae79b87aaa.webp&#34;
               width=&#34;504&#34;
               height=&#34;182&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Para &lt;strong&gt;rodar&lt;/strong&gt; uma das LLMs com o código:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run &amp;lt;Nome_da_LLM&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;No caso da Phi3&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama run phi3.5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Mas antes de tudo, para fins de demostração, vou garantir que não está ocorrendo comunicação com a internet:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Desligando o WiFi&#34; srcset=&#34;
               /post/ollama/wifi_hu0518b1696c86dec125af7946952d8ffb_11007_f619ccb51aa24483439161d2913aca46.webp 400w,
               /post/ollama/wifi_hu0518b1696c86dec125af7946952d8ffb_11007_21da799eb1e940cdb3ae4d8e3e025a8f.webp 760w,
               /post/ollama/wifi_hu0518b1696c86dec125af7946952d8ffb_11007_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/wifi_hu0518b1696c86dec125af7946952d8ffb_11007_f619ccb51aa24483439161d2913aca46.webp&#34;
               width=&#34;736&#34;
               height=&#34;255&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Aqui vou pedir para que ele me gere um código Python para connectar a uma base do MySQL:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Exemplo de Prompt&#34; srcset=&#34;
               /post/ollama/exemplophi_hua192235b4453e72befac9f1c824da6f4_121326_8a5d45d3857871cd2450e252e9b3b157.webp 400w,
               /post/ollama/exemplophi_hua192235b4453e72befac9f1c824da6f4_121326_8caf1b0bbf85d5d4893be3aced9650a2.webp 760w,
               /post/ollama/exemplophi_hua192235b4453e72befac9f1c824da6f4_121326_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/exemplophi_hua192235b4453e72befac9f1c824da6f4_121326_8a5d45d3857871cd2450e252e9b3b157.webp&#34;
               width=&#34;760&#34;
               height=&#34;708&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Não vou me extender na utilização dele ou de outro modelo, mas é possível utilizar o próprio terminal para conversar com a LLM, e existem formas de conversar via interface gráfica, o que fica para um próximo post.&lt;/p&gt;
&lt;p&gt;Agora para avaliar o uso computacional da minha máquina, vou utilizando o utilitário Nvidia-smi em que é possivel ver o quanto ele está utilizando os recursos da GPU&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Uso GPU&#34; srcset=&#34;
               /post/ollama/nvidia_hubc3997401dc88a6996c26f54a459afaf_41310_98f0f646c268241808fa529e6edb22a6.webp 400w,
               /post/ollama/nvidia_hubc3997401dc88a6996c26f54a459afaf_41310_20e94217650cb76e36823c727e3031ae.webp 760w,
               /post/ollama/nvidia_hubc3997401dc88a6996c26f54a459afaf_41310_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/nvidia_hubc3997401dc88a6996c26f54a459afaf_41310_98f0f646c268241808fa529e6edb22a6.webp&#34;
               width=&#34;584&#34;
               height=&#34;497&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;E em relação ao uso computacional da CPU e do consumo de memória RAM ele não ficou &amp;ldquo;tão pesado&amp;rdquo;, ,as lembrando que o Phi3.5 é um modelo particularmente pequeno. O print abaixo apresenta o consumo computacional durante uma inferencia:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Durante Inferencia&#34; srcset=&#34;
               /post/ollama/inferencia_hu3b6af082a6dbe67da50599503b38f4b2_257880_8d493d241e88bed9925f02aac390d399.webp 400w,
               /post/ollama/inferencia_hu3b6af082a6dbe67da50599503b38f4b2_257880_70f92590570ac49bb4f09ae10b0d960f.webp 760w,
               /post/ollama/inferencia_hu3b6af082a6dbe67da50599503b38f4b2_257880_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/inferencia_hu3b6af082a6dbe67da50599503b38f4b2_257880_8d493d241e88bed9925f02aac390d399.webp&#34;
               width=&#34;760&#34;
               height=&#34;426&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Agora para &lt;em&gt;sair&lt;/em&gt; do Ollama, basta digitar no prompt:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/bye
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;bye&#34; srcset=&#34;
               /post/ollama/bye_huea65a25b44a75455c77df55c2e60a2dd_4744_14ba64c8fba48d1dd9817ed23edb5451.webp 400w,
               /post/ollama/bye_huea65a25b44a75455c77df55c2e60a2dd_4744_aae2e8326aec6bfc92bb95f4ee43eb92.webp 760w,
               /post/ollama/bye_huea65a25b44a75455c77df55c2e60a2dd_4744_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/bye_huea65a25b44a75455c77df55c2e60a2dd_4744_14ba64c8fba48d1dd9817ed23edb5451.webp&#34;
               width=&#34;229&#34;
               height=&#34;62&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;E para gerenciar e &lt;em&gt;deletar os modelos LLMs&lt;/em&gt;, é possivel listar e solicitar a remoção da imagem.
PS: peço desculpas na imagem abaixo por que eu digitei um comando errado, por isto ocultei o mesmo, para evitar confusão.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ollama rm &amp;lt;nome_da_LLM&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Deletando um LLM&#34; srcset=&#34;
               /post/ollama/delete_hubafa5203375a5bde6d5718029e372e93_32239_597180a4a0827ea1566da51c787c39a1.webp 400w,
               /post/ollama/delete_hubafa5203375a5bde6d5718029e372e93_32239_0055384a32f8b9e835b6229d359262d6.webp 760w,
               /post/ollama/delete_hubafa5203375a5bde6d5718029e372e93_32239_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://lgrando1.github.io/post/ollama/delete_hubafa5203375a5bde6d5718029e372e93_32239_597180a4a0827ea1566da51c787c39a1.webp&#34;
               width=&#34;477&#34;
               height=&#34;333&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Este tutorial aborda apenas alguns aspectos do uso do Ollama, o &lt;a href=&#34;https://itsfoss.com/ollama-setup-linux/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutorial que serviu como base&lt;/a&gt; para este experimento possui mais informações, como utilizar a interface gráfica com Docker e também como desinstalar o Ollama. Assim você tem um assistente local para lhe ajudar em tarefas simples. Ontem eu testei o uso do Llamma 3.1 para criar um banco de dados no MySQL e para implementar um código Python para interagir com este banco de dados e o código proposto funcionou. Mas é preciso testar mais.&lt;/p&gt;
&lt;p&gt;Sucesso a todos!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dicas de Engenharia de Prompt</title>
      <link>https://lgrando1.github.io/post/prompt1/</link>
      <pubDate>Sat, 27 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/prompt1/</guid>
      <description>&lt;p&gt;Outros posts sobre o tema em:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/hface/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Como Criar um Pipeline em Python para Testar Modelos no Hugging Face&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollama/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 1 - Instalando o Ollama no Linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollamawin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 2 - Instalando o Ollama no Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/llmandroid/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 3 - Instalando LLMs Off-line no Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Realizei recentemente o curso &lt;a href=&#34;https://www.coursera.org/learn/prompt-engineering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Prompt Engineering for ChatGPT&lt;/em&gt;&lt;/a&gt; e gostaria de compartilhar algumas anotações que realizei durante o mesmo.&lt;/p&gt;
&lt;p&gt;Estas ferramentas não podem ser consideradas como &lt;a href=&#34;https://chat.openai.com/share/36071465-b59a-44e1-a494-eaba36edc4cd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fonte de fatos&lt;/a&gt;, mas são excelentes como suporte para ideias e quem sabe para tirar da gaveta aquela ideia de um livro.&lt;/p&gt;
&lt;p&gt;O objetivo desta série é criar postagens com quatro estratégias por post. Estou utilizando como exemplo o Chat-GPT em sua versão grátis, mas você pode testar em qualquer outra ferramenta.&lt;/p&gt;
&lt;p&gt;Caso queira conhecer melhor o funcionamento destas ferramentas, recomendo o &lt;a href=&#34;https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;texto do Stephen Wolfram&lt;/a&gt; e o curso &lt;a href=&#34;https://www.coursera.org/learn/prompt-engineering&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Prompt Engineering for ChatGPT&lt;/em&gt;&lt;/a&gt; que pode ser auditado gratuitamente no Coursera.&lt;/p&gt;
&lt;p&gt;Os links incluem exemplos de cada item.&lt;/p&gt;
&lt;h2 id=&#34;1---são-ferramentas-estocásticas-por-isto-pode-não-ocorrer-repetitividade-nas-respostas-já-que-a-sua-resposta-depende-de-como-elas-foram-treinadas&#34;&gt;1 - São ferramentas estocásticas, por isto pode não ocorrer &lt;strong&gt;repetitividade&lt;/strong&gt; nas respostas, já que a sua resposta depende de como elas foram treinadas:&lt;/h2&gt;
&lt;p&gt;Conforme você realiza o prompt, as ferramentas podem responder de formas diferentes, por isto é importante o refino da sua questão e testar várias estratégias.&lt;/p&gt;
&lt;p&gt;Ainda considerando a pergunta, quantos prêmios Nobéis o Brasil já foi agraciado? O &lt;a href=&#34;https://chat.openai.com/share/36071465-b59a-44e1-a494-eaba36edc4cd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;exemplo 1&lt;/a&gt; e o &lt;a href=&#34;https://chat.openai.com/share/9f91d34d-87ec-49d1-bb8e-b533a0cc0972&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;exemplo 2&lt;/a&gt; apresentam respostas distintas para a mesma questão.&lt;/p&gt;
&lt;h2 id=&#34;2---você-pode-solicitar-a-esta-ferramenta-para-que-ela-aja-conforme-um-personagem-ex-professor-consultor-etc-e-que-a-resposta-seja-direcionada-para-determinado-público-jovens-da-terceira-idade-adolescente&#34;&gt;2 - Você pode solicitar a esta ferramenta para que ela aja conforme um personagem (ex: professor, consultor, etc.) e que a resposta seja direcionada para determinado público (jovens da terceira idade, adolescente).&lt;/h2&gt;
&lt;p&gt;A estrutura deste prompt é:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aja como P e faça A&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Onde &lt;strong&gt;P&lt;/strong&gt; é igual ao personagem que você deseja e &lt;strong&gt;A&lt;/strong&gt; ação que você espera dele.&lt;/p&gt;
&lt;p&gt;Neste &lt;a href=&#34;https://chat.openai.com/share/21dfd00b-cd05-44eb-9b57-3982f936b991&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;exemplo&lt;/a&gt;, vou pedir para ele agir como um professor de Línguas, depois vou pedir para ele explicar o meu erro usando um exemplo de obra literária e depois para ele contextualizar um assunto atual para um cidadão do ano 1700.&lt;/p&gt;
&lt;h2 id=&#34;3---você-pode-enviar-novas-informações-para-o-prompt&#34;&gt;3 - Você pode enviar novas informações para o Prompt.&lt;/h2&gt;
&lt;p&gt;Estas ferramentas possuem uma limitação do processo de treinamento. Você pode fornecer novas informações para que ele possa aprimorar a resposta.&lt;/p&gt;
&lt;p&gt;Neste &lt;a href=&#34;https://chat.openai.com/share/7adc6484-d5a0-4545-bbf9-9256a82ac82d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;exemplo&lt;/a&gt; pedi para ele os presidentes que governaram o Brasil entre os anos 2000 a 2024 e solicitei atualização das informações com o novo presidente.&lt;/p&gt;
&lt;h2 id=&#34;4---refinamento-de-questões&#34;&gt;4 - Refinamento de questões.&lt;/h2&gt;
&lt;p&gt;Observe que a clareza com que você faz os questionamentos é importante para que você tenha respostas mais próximas do que deseja. Não adianta você pedir: Quais foram os presidentes?, se você quer uma resposta limitada por tempo. Mas você &lt;a href=&#34;https://chat.openai.com/share/34a42de3-e9c8-4d69-8941-643472f973cb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pode pedir&lt;/a&gt; para ele como melhorar sua pergunta.&lt;/p&gt;
&lt;p&gt;Por enquanto são estas dicas, vimos que podem ocorrer variações nas respostas, que estas ferramentas podem agir como determinado personagem para atingir um público específico, que você pode treinar a ferramenta localmente com novas informações para que sua resposta seja mais atual e que a própria ferramenta pode lhe ajudar a refinar as suas questões.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Testando Modelos de IA com o HuggingFace.</title>
      <link>https://lgrando1.github.io/post/hface/</link>
      <pubDate>Sun, 24 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/hface/</guid>
      <description>&lt;p&gt;Outros posts sobre o tema em:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/prompt1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dicas de Engenharia de Prompt&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollama/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 1 - Instalando o Ollama no Linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/ollamawin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 2 - Instalando o Ollama no Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lgrando1.github.io/post/llmandroid/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parte 3 - Instalando LLMs Off-line no Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A plataforma &lt;a href=&#34;https://huggingface.co/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Hugging Face&lt;/strong&gt;&lt;/a&gt; é uma portal onde a comunidade de aprendizado de máquina colabora com modelos, conjunto de dados e aplicações.&lt;/p&gt;
&lt;p&gt;Ao acessar o site e clicar no link &lt;a href=&#34;https://huggingface.co/models&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Models&lt;/a&gt; é possível buscar por variados modelos voltados para várias tarefas de aprendizado de máquina, visão computacional, processamento natural de linguagem, áudio, dados tabulares, aprendizado por reforço e outros tipos.&lt;/p&gt;
&lt;p&gt;Neste post apresentaremos uma introdução de como utilizar estas bibliotecas em sua máquina (ou no Google Colab). Como exemplo, é demostrado a realização de duas tarefas: o preenchimento de máscaras de texto (completar um espaço de um texto) e o resumo de um texto.&lt;/p&gt;
&lt;p&gt;São dois modelos/exemplos simples, mas o objetivo é realmente despertar a curiosidade em conhecer mais sobre esta plataforma.&lt;/p&gt;
&lt;p&gt;Algumas considerações:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ao baixar o modelo em sua máquina, alguns modelos são grandes, como o segundo modelo deste tutorial que possui mais do que 1,5 GB. Neste &lt;a href=&#34;https://huggingface.co/docs/huggingface_hub/en/guides/manage-cache&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt; é possível ver como gerenciar o cache destes modelos;&lt;/li&gt;
&lt;li&gt;Se atente ao modelo que você testará, pois já foram encontrados &lt;a href=&#34;https://www.bleepingcomputer.com/news/security/malicious-ai-models-on-hugging-face-backdoor-users-machines/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;problemas de segurança&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Se atente também nas licenças de conteúdo dos modelos e também possíveis dependências. Se atente a documentação presente em cada página dos modelos;&lt;/li&gt;
&lt;li&gt;Alguns modelos de aprendizados de máquinas exigem bastantes recursos computacionais, ao escrever este post, várias vezes o Jupyter acabou resetando. Apenas para comparativo, este computador é um Core i5 de nona geração (Intel i5 - 9300H) e 8 GB de RAM. Infelizmente ainda não consegui ativar a GPU para tarefas de Machine Learning no Linux. No Google Colab é possível ativar o &lt;a href=&#34;https://colab.research.google.com/notebooks/gpu.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;suporte ao GPU&lt;/a&gt; mesmo no tier grátis.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Alerta feitos, vamos aos modelos:&lt;/p&gt;
&lt;p&gt;Primeiro é necessário a biblioteca &lt;a href=&#34;https://huggingface.co/docs/transformers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Transformers&lt;/a&gt; para poder baixar e treinais os modelos pré-treinados.&lt;/p&gt;
&lt;p&gt;No momento da escrita deste post estão disponíveis 564772 modelos.&lt;/p&gt;
&lt;p&gt;Aqui esta presente a &lt;a href=&#34;https://huggingface.co/docs/transformers/en/installation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentação&lt;/a&gt; de como instalar esta biblioteca.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;transformers&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;transformers&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#Apenas para suprimir erros, não nescessário. &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;logging&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getLogger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;transformers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setLevel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ERROR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tarefa-1---preenchimento-de-máscaras&#34;&gt;Tarefa 1 - preenchimento de máscaras&lt;/h2&gt;
&lt;p&gt;Para realizar a tarefa de &lt;strong&gt;preenchimento de máscaras&lt;/strong&gt;, utilizaremos o modelo &lt;a href=&#34;https://huggingface.co/neuralmind/bert-base-portuguese-cased&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BERTimbau Base (aka &amp;ldquo;bert-base-portuguese-cased&amp;rdquo;&lt;/a&gt; [1]&lt;/p&gt;
&lt;p&gt;Iremos utilizar neste caso a versão base.&lt;/p&gt;
&lt;p&gt;A tarefa realizada será &amp;ldquo;fill-mask&amp;rdquo; e iremos pedir que ele devolva 5 respostas para a frase &amp;ldquo;Batatinha quando nasce, esparrama pelo [MASK]&amp;rdquo; onde [MASK] é o texto que será preenchido pelo token.&lt;/p&gt;
&lt;p&gt;[1] SOUZA, Fábio e NOGUEIRA, Rodrigo e LOTUFO, &lt;strong&gt;Roberto. BERTimbau: pretrained BERT models for Brazilian Portuguese.&lt;/strong&gt; 2020, [S.l: s.n.], 2020.&lt;/p&gt;
&lt;p&gt;A primeira linha do código abaixo indicar a tarefa a ser executada e o modelo a ser utilizado e a segunda linha aplica o modelo para o texto escolhido.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mascarar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;fill-mask&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;neuralmind/bert-base-portuguese-cased&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;texto&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mascarar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Batatinha quando nasce, esparrama pelo [MASK]&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;texto&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;texto&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{&#39;score&#39;: 0.3925571143627167, &#39;token&#39;: 8105, &#39;token_str&#39;: &#39;chão&#39;, &#39;sequence&#39;: &#39;Batatinha quando nasce, esparrama pelo chão&#39;}
{&#39;score&#39;: 0.10256581008434296, &#39;token&#39;: 1831, &#39;token_str&#39;: &#39;corpo&#39;, &#39;sequence&#39;: &#39;Batatinha quando nasce, esparrama pelo corpo&#39;}
{&#39;score&#39;: 0.05736977979540825, &#39;token&#39;: 1147, &#39;token_str&#39;: &#39;mundo&#39;, &#39;sequence&#39;: &#39;Batatinha quando nasce, esparrama pelo mundo&#39;}
{&#39;score&#39;: 0.047487251460552216, &#39;token&#39;: 388, &#39;token_str&#39;: &#39;ar&#39;, &#39;sequence&#39;: &#39;Batatinha quando nasce, esparrama pelo ar&#39;}
{&#39;score&#39;: 0.023149045184254646, &#39;token&#39;: 9169, &#39;token_str&#39;: &#39;rosto&#39;, &#39;sequence&#39;: &#39;Batatinha quando nasce, esparrama pelo rosto&#39;}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Observe nas resposta acima que o maior &amp;ldquo;score&amp;rdquo; foi para a frase que contém o token &amp;ldquo;chão&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;tarefa-2---resumo-de-textos&#34;&gt;Tarefa 2 - Resumo de textos&lt;/h2&gt;
&lt;p&gt;Para realizar o processo de &lt;strong&gt;resumo de texto&lt;/strong&gt; (&amp;ldquo;summarization&amp;rdquo;), iremos utilizar como exemplo o modelo &lt;a href=&#34;https://huggingface.co/facebook/bart-large-cnn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;facebook/bart-large-cnn&lt;/a&gt; [2]&lt;/p&gt;
&lt;p&gt;Utilizaremos o texto que está presente na própria página do modelo.&lt;/p&gt;
&lt;p&gt;[2] LEWIS, Mike e colab. &lt;strong&gt;BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.&lt;/strong&gt; CoRR, v. abs/1910.13461, 2019. Disponível em: &lt;a href=&#34;http://arxiv.org/abs/1910.13461&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://arxiv.org/abs/1910.13461&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;resumir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pipeline&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;summarization&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;facebook/bart-large-cnn&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;texto&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;building, and the tallest structure in Paris. Its base is square, measuring 125 metres 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;(410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;Monument to become the tallest man-made structure in the world, a title it held for 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;41 years until the Chrysler Building in New York City was finished in 1930. 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;It was the first structure to reach a height of 300 metres. Due to the addition of a 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;second tallest free-standing structure in France after the Millau Viaduct.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;resumo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;resumir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;texto&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;40&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min_length&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;do_sample&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;resumo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[{&#39;summary_text&#39;: &#39;The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. Its base is square, measuring 125 metres (410 ft&#39;}]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;conclusão&#34;&gt;Conclusão&lt;/h2&gt;
&lt;p&gt;Este post apresentou como testar modelos de aprendizado de máquinas utilizando a biblioteca Transformers do Hugging Face.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Classificação de imagens com o TensorFlow.</title>
      <link>https://lgrando1.github.io/post/pythoncv/</link>
      <pubDate>Sat, 23 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://lgrando1.github.io/post/pythoncv/</guid>
      <description>&lt;p&gt;Neste post é apresentado uma rotina de aprendizado de máquina supervisionado utilizando a biblioteca TensorFlow para realizar o reconhecimento e classificação de imagens da base de dados &lt;a href=&#34;https://en.wikipedia.org/wiki/MNIST_database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MNIST&lt;/a&gt;. Esta base de dados consiste em imagens de numeros escritos a mão e seus respectivos rótulos. A idéia deste post é treinar um modelo de rede neural que reconheça os padrões destas imagens e as classifiquem com o respectivo número.&lt;/p&gt;
&lt;p&gt;O conteúdo desta atividade de classificação é composto de:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Importar as bibliotecas;&lt;/li&gt;
&lt;li&gt;Importar o conjunto de dados e dividi-los entre base treino e de teste;&lt;/li&gt;
&lt;li&gt;Aplicar o processo de Hot Encoding nas classes de respostas;&lt;/li&gt;
&lt;li&gt;Pré-processamento dos dados para que possam ser uitilizados no treinamento da rede;&lt;/li&gt;
&lt;li&gt;Criação do modelo de rede neural;&lt;/li&gt;
&lt;li&gt;Treinamento do modelo com os dados de treinamento;&lt;/li&gt;
&lt;li&gt;Realizar a predição e comparação com os dados de teste.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;1-importação-das-bibliotecas-necessárias-incluindo-o-tensorflowhttpswwwtensorfloworghlpt-br&#34;&gt;1. Importação das bibliotecas necessárias, incluindo o &lt;a href=&#34;https://www.tensorflow.org/?hl=pt-br&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TensorFlow&lt;/a&gt;&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tf&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;numpy&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;np&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;compat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;set_verbosity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;compat&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logging&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ERROR&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Using TensorFlow version&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;__version__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#Processo de hot-encoding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow.keras.utils&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to_categorical&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#para criar as camadas do modelo de rede neural&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow.keras.models&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow.keras.layers&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Dense&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#para visualizar as imagens&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;matplotlib&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pyplot&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;%&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;matplotlib&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;inline&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2024-03-24 10:02:13.310353: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-03-24 10:02:13.370354: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-03-24 10:02:13.371713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-24 10:02:14.341836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT


Using TensorFlow version 2.13.1
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2-importar-a-base-de-dados-e-dividi-la-em-bases-treino-e-de-teste&#34;&gt;2: Importar a base de dados e dividi-la em bases treino e de teste&lt;/h2&gt;
&lt;p&gt;A própria biblioteca &lt;a href=&#34;https://www.tensorflow.org/datasets/catalog/mnist?hl=pt-br&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tensorflow&lt;/a&gt; já disponibiliza esta base.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;tensorflow.keras.datasets&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mnist&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mnist&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;load_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;dimensões-dos-arrays-importados&#34;&gt;Dimensões dos arrays importados&lt;/h3&gt;
&lt;p&gt;A base de dados MNIST é composta por 70000 imagens em escala de cinza de dimensões de 28 por 28 e seus respectivos rótulos. Neste trabalho esta base foi dividida com 60000 instancias de treino e 10000 de teste para poder verificar a performance do treinamento. Cada valor dos pixels representam um valor integral (entre 0 a 255) na escala de cinza.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;x_train shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y_train shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;x_test shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y_test shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;x_train shape (60000, 28, 28)
y_train shape (60000,)
x_test shape (10000, 28, 28)
y_test shape (10000,)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;visualizando-uma-imagem-presente-na-base-de-treino&#34;&gt;Visualizando uma imagem presente na base de treino&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Apresentando uma imagem da base de treino.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imshow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmap&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;binary&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./index_9_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;para-ver-o-seu-rótulo-de-treino&#34;&gt;Para ver o seu rótulo de treino:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# O valor da classe na posição 1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#valor 5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#valor 0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;5
0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;para-ver-todos-os-rótulos-presentes-na-base-de-treino&#34;&gt;Para ver todos os rótulos presentes na base de treino:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Os valores presentes na classe de treino&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;3---processo-de-hot-encoding-nas-classes&#34;&gt;3 - Processo de hot encoding nas classes.&lt;/h2&gt;
&lt;p&gt;Para que as classes de respostas possam passar pelo processo de treinamento e de testes, é necessario aplicar o processo de pré-processamento de hot encoding (criação de variaveis dummies) nas classes de respostas.&lt;/p&gt;
&lt;h3 id=&#34;codificando-os-rótulos&#34;&gt;Codificando os rótulos&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_train_encoded&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to_categorical&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;y_test_encoded&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;to_categorical&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;conhecendo-as-dimensões-das-bases-de-dados-codificadas&#34;&gt;Conhecendo as dimensões das bases de dados codificadas&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y_train_encoded shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train_encoded&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;y_test_encoded shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test_encoded&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;y_train_encoded shape (60000, 10)
y_test_encoded shape (10000, 10)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;visualizando-um-rótulo-codificado&#34;&gt;Visualizando um rótulo codificado.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train_encoded&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#valor 5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y_train_encoded&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#valor 0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-pré-processamento&#34;&gt;4 Pré-processamento.&lt;/h2&gt;
&lt;h3 id=&#34;transformar-a-matriz-de-2-dimensões-28x28-pixels-com-valores-de-0-a-255-em-um-uníco-vetor-de-dimensão-784&#34;&gt;Transformar a matriz de 2 dimensões (28x28 pixels com valores de 0 a 255) em um uníco vetor de dimensão 784.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_train_reshaped&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;60000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;784&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_test_reshaped&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reshape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;784&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;x_train_reshaped_shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_train_reshaped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;x_test_reshaped_shape&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x_test_reshaped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;x_train_reshaped_shape (60000, 784)
x_test_reshaped_shape (10000, 784)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;normalização-dos-a&#34;&gt;Normalização dos a&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train_reshaped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_std&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;std&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train_reshaped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;epsilon&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1e-10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_train_norm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train_reshaped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_std&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epsilon&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x_test_norm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test_reshaped&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_mean&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_std&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epsilon&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;5-criando-o-modelo-de-rede-neural&#34;&gt;5: Criando o modelo de rede neural.&lt;/h2&gt;
&lt;h3 id=&#34;modelo-será-composto-de-uma-camada-de-entrada-uma-camada-interna-oculta-e-uma-camada-de-saída&#34;&gt;Modelo será composto de uma camada de entrada, uma camada interna oculta e uma camada de saída.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Sequential&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Dense&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;activation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_shape&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;784&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,)),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Dense&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;activation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;relu&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Dense&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;activation&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;softmax&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;2024-03-24 10:02:16.922990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-03-24 10:02:16.923710: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;compilando-o-modelo&#34;&gt;Compilando o modelo&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;compile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;optimizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;sgd&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;categorical_crossentropy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;metrics&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;accuracy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 56)                43960     
                                                                 
 dense_1 (Dense)             (None, 128)               7296      
                                                                 
 dense_2 (Dense)             (None, 10)                1290      
                                                                 
=================================================================
Total params: 52546 (205.26 KB)
Trainable params: 52546 (205.26 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;6---treinando-o-modelo&#34;&gt;6 - Treinando o modelo&lt;/h2&gt;
&lt;h3 id=&#34;treinar-o-modelo-com-o-base-de-dados-de-treino-normalizado-e-com-o-a-base-de-classe-de-treino-codificado-o-valor-de-epoch-é-a-quantidade-de-vezes-que-os-dados-passam-pela-rede&#34;&gt;Treinar o modelo com o base de dados de treino normalizado e com o a base de classe de treino codificado. O valor de epoch é a quantidade de vezes que os dados passam pela rede.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_train_norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_train_encoded&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;epochs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Epoch 1/2


2024-03-24 10:02:17.328579: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.


1875/1875 [==============================] - 3s 2ms/step - loss: 0.4276 - accuracy: 0.8749
Epoch 2/2
1875/1875 [==============================] - 3s 1ms/step - loss: 0.2094 - accuracy: 0.9380





&amp;lt;keras.src.callbacks.History at 0x7fa8104c2400&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;avaliando-a-performance-do-modelo-na-base-de-teste&#34;&gt;Avaliando a performance do modelo na base de teste.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accuracy&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;evaluate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test_norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test_encoded&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Test set accuracy:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;accuracy&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 1s 1ms/step - loss: 0.1733 - accuracy: 0.9484
Test set accuracy: 94.84000205993652
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;7---predição&#34;&gt;7 - Predição&lt;/h2&gt;
&lt;h3 id=&#34;realizar-a-predição-na-base-de-teste-normalizada&#34;&gt;Realizar a predição na base de teste normalizada&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;predit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test_norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Shape of preds:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predit&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#Para visualizar as previsões:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Valores previstos:&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;313/313 [==============================] - 0s 1ms/step
Shape of preds: (10000, 10)
Valores previstos: [7 2 1 ... 4 5 6]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;visualizar-os-36-primeiros-valores-da-base-de-teste-e-u-comparar-entre-a-resposta-conhecida-e-a-predição-feita-pelo-modelo&#34;&gt;Visualizar os 36 primeiros valores da base de teste e u comparar entre a resposta conhecida e a predição feita pelo modelo.&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figure&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;figsize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;16&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;start_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;36&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;grid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;yticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xticks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argmax&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;valor_teste&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start_index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pred&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valor_teste&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;b&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlabel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;i = &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;, predito=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;, rótulo=&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start_index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pred&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;valor_teste&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;color&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;col&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imshow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;start_index&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmap&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;binary&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;plt&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./index_35_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Nas primeiras 36 imagens, as imagens de indíce 8 e 33 foram preditas de forma incorreta por o modelo implementado.&lt;/p&gt;
&lt;h2 id=&#34;conclusão&#34;&gt;Conclusão:&lt;/h2&gt;
&lt;p&gt;Este post apresentou um fluxo de trabalho para tarefas de classificação de imagens utilizando o TensorFlow, treinando-o para reconhecer os padrões dos dados presentes nesta base de dados.&lt;/p&gt;
&lt;p&gt;Foi realizado um pré-processamento dos dados para que os mesmos possam ser aplicado no treinamento da rede neural, criou-se o modelo, treinou o mesmo e verificou a performance deste treino comparando os valores preditos com os valores préviamente rotulados.&lt;/p&gt;
&lt;p&gt;Alterações em alguns hiperparâmetros como por exemplo o tipo de otimizador, na geometria da rede, na quantidade de epochs podem ser utilizados para melhorar os resultados presentes neste post.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
